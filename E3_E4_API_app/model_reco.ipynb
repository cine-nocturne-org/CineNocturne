{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19d8a9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import xgboost as xgb\n",
    "import mlflow\n",
    "import mlflow.xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fff6511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# ‚öôÔ∏è Config\n",
    "# =========================\n",
    "DATABASE_URL = \"mysql+pymysql://louve:%40Marley080922@mysql-louve.alwaysdata.net/louve_movies\"\n",
    "SQL_QUERY = \"\"\"\n",
    "SELECT movie_id, title, synopsis, rating, genres, release_year\n",
    "FROM movies\n",
    "WHERE synopsis IS NOT NULL\n",
    "\"\"\"\n",
    "\n",
    "EXPERIMENT_NAME = \"movies_hybrid_like_dislike\"\n",
    "RUN_NAME = \"xgb_hybrid_like_dislike\"\n",
    "\n",
    "LIKE_THRESHOLD = 4.0          # seuil like/dislike\n",
    "TFIDF_MAX_FEATURES = 5000\n",
    "SVD_COMPONENTS = 100\n",
    "RANDOM_STATE = 42\n",
    "SAMPLE_SIZE = 10_000          # None = tout le dataset\n",
    "\n",
    "ARTIFACT_DIR = \"model\"\n",
    "os.makedirs(ARTIFACT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29b37246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>synopsis</th>\n",
       "      <th>rating</th>\n",
       "      <th>genres</th>\n",
       "      <th>release_year</th>\n",
       "      <th>synopsis_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>911430</td>\n",
       "      <td>F1</td>\n",
       "      <td>Racing legend Sonny Hayes is coaxed out of ret...</td>\n",
       "      <td>7.8</td>\n",
       "      <td>Action</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>racing legend sonny hayes is coaxed out of ret...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>575265</td>\n",
       "      <td>Mission: Impossible - The Final Reckoning</td>\n",
       "      <td>Ethan Hunt and team continue their search for ...</td>\n",
       "      <td>7.2</td>\n",
       "      <td>Action</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>ethan hunt and team continue their search for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1061474</td>\n",
       "      <td>Superman</td>\n",
       "      <td>Superman, a journalist in Metropolis, embarks ...</td>\n",
       "      <td>7.6</td>\n",
       "      <td>Action</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>superman  a journalist in metropolis  embarks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1151334</td>\n",
       "      <td>Eenie Meanie</td>\n",
       "      <td>A former teenage getaway driver gets dragged b...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>Action</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>a former teenage getaway driver gets dragged b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1234821</td>\n",
       "      <td>Jurassic World Rebirth</td>\n",
       "      <td>Five years after the events of Jurassic World ...</td>\n",
       "      <td>6.4</td>\n",
       "      <td>Action</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>five years after the events of jurassic world ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                                      title  \\\n",
       "0    911430                                         F1   \n",
       "1    575265  Mission: Impossible - The Final Reckoning   \n",
       "2   1061474                                   Superman   \n",
       "3   1151334                               Eenie Meanie   \n",
       "4   1234821                     Jurassic World Rebirth   \n",
       "\n",
       "                                            synopsis  rating  genres  \\\n",
       "0  Racing legend Sonny Hayes is coaxed out of ret...     7.8  Action   \n",
       "1  Ethan Hunt and team continue their search for ...     7.2  Action   \n",
       "2  Superman, a journalist in Metropolis, embarks ...     7.6  Action   \n",
       "3  A former teenage getaway driver gets dragged b...     6.8  Action   \n",
       "4  Five years after the events of Jurassic World ...     6.4  Action   \n",
       "\n",
       "   release_year                                     synopsis_clean  \n",
       "0        2025.0  racing legend sonny hayes is coaxed out of ret...  \n",
       "1        2025.0  ethan hunt and team continue their search for ...  \n",
       "2        2025.0  superman  a journalist in metropolis  embarks ...  \n",
       "3        2025.0  a former teenage getaway driver gets dragged b...  \n",
       "4        2025.0  five years after the events of jurassic world ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_text(text: str) -> str:\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \" \", text)\n",
    "    return text\n",
    "\n",
    "engine = create_engine(DATABASE_URL)\n",
    "df = pd.read_sql(SQL_QUERY, engine)\n",
    "\n",
    "df[\"synopsis_clean\"] = df[\"synopsis\"].fillna(\"\").apply(preprocess_text)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a37894f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=TFIDF_MAX_FEATURES, stop_words=\"english\")\n",
    "tfidf_matrix_full = vectorizer.fit_transform(df[\"synopsis_clean\"])\n",
    "\n",
    "# R√©duction SVD\n",
    "svd = TruncatedSVD(n_components=SVD_COMPONENTS, random_state=RANDOM_STATE)\n",
    "tfidf_svd_full = svd.fit_transform(tfidf_matrix_full)\n",
    "\n",
    "# Genres\n",
    "df[\"genres_list\"] = df[\"genres\"].fillna(\"\").apply(lambda x: x.split(\"|\"))\n",
    "mlb = MultiLabelBinarizer()\n",
    "genres_encoded_full = mlb.fit_transform(df[\"genres_list\"])\n",
    "\n",
    "# Ann√©e\n",
    "scaler_year = StandardScaler()\n",
    "year_scaled_full = scaler_year.fit_transform(\n",
    "    df[[\"release_year\"]].fillna(df[\"release_year\"].mean())\n",
    ")\n",
    "\n",
    "# Similarit√© kNN\n",
    "nn_full = NearestNeighbors(metric=\"cosine\", algorithm=\"brute\")\n",
    "nn_full.fit(tfidf_matrix_full)\n",
    "distances_full, _ = nn_full.kneighbors(tfidf_matrix_full, n_neighbors=6)\n",
    "neighbor_scores_full = 1 - distances_full[:, 1:]\n",
    "\n",
    "sim_mean_full = neighbor_scores_full.mean(axis=1)\n",
    "sim_max_full = neighbor_scores_full.max(axis=1)\n",
    "sim_min_full = neighbor_scores_full.min(axis=1)\n",
    "sim_std_full = neighbor_scores_full.std(axis=1)\n",
    "\n",
    "sim_stats_full = np.column_stack([sim_mean_full, sim_max_full, sim_min_full, sim_std_full])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f30b325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 124), (10000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label binaire\n",
    "y = (df[\"rating\"] >= LIKE_THRESHOLD).astype(int).to_numpy()\n",
    "\n",
    "# Features\n",
    "X_full = np.column_stack([tfidf_svd_full, genres_encoded_full, year_scaled_full, sim_stats_full])\n",
    "\n",
    "# √âchantillonnage optionnel\n",
    "if SAMPLE_SIZE and SAMPLE_SIZE < len(df):\n",
    "    rng = np.random.default_rng(RANDOM_STATE)\n",
    "    idx = rng.choice(len(df), size=SAMPLE_SIZE, replace=False)\n",
    "    X = X_full[idx]\n",
    "    y = y[idx]\n",
    "    df_used = df.iloc[idx].reset_index(drop=True)\n",
    "else:\n",
    "    X = X_full\n",
    "    df_used = df.reset_index(drop=True)\n",
    "\n",
    "X.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f20115f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos: 4903, Neg: 3097, scale_pos_weight=0.63\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "n_pos = int((y_train == 1).sum())\n",
    "n_neg = int((y_train == 0).sum())\n",
    "scale_pos_weight = (n_neg / n_pos) if n_pos > 0 else 1.0\n",
    "\n",
    "print(f\"Pos: {n_pos}, Neg: {n_neg}, scale_pos_weight={scale_pos_weight:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e66b94b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/28 09:55:59 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh(<full-path-to-git-executable>)\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial message can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|silent|none|n|0: for no message or exception\n",
      "    - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)\n",
      "    - error|e|exception|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n",
      "c:\\Users\\loulo\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [09:55:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "2025/08/28 09:56:01 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "c:\\Users\\loulo\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:1028: UserWarning: [09:56:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\c_api\\c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "2025/08/28 09:56:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Metrics ‚Äî ACC: 0.6675 | ROC-AUC: 0.6770 | P: 0.7049 | R: 0.7871 | F1: 0.7437\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME):\n",
    "    params = {\n",
    "        \"n_estimators\": 300,\n",
    "        \"max_depth\": 6,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"random_state\": RANDOM_STATE,\n",
    "        \"n_jobs\": -1,\n",
    "        \"use_label_encoder\": False,\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"scale_pos_weight\": scale_pos_weight,\n",
    "    }\n",
    "    mlflow.log_param(\"like_threshold\", LIKE_THRESHOLD)\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    roc = roc_auc_score(y_test, y_prob)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    mlflow.log_metric(\"roc_auc\", roc)\n",
    "    mlflow.log_metric(\"precision\", prec)\n",
    "    mlflow.log_metric(\"recall\", rec)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "    mlflow.xgboost.log_model(model, \"xgb_hybrid_like_dislike_model\")\n",
    "\n",
    "print(f\"‚úÖ Metrics ‚Äî ACC: {acc:.4f} | ROC-AUC: {roc:.4f} | P: {prec:.4f} | R: {rec:.4f} | F1: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "975a6604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[370 404]\n",
      " [261 965]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.48      0.53       774\n",
      "           1       0.70      0.79      0.74      1226\n",
      "\n",
      "    accuracy                           0.67      2000\n",
      "   macro avg       0.65      0.63      0.64      2000\n",
      "weighted avg       0.66      0.67      0.66      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(\"\\nClassification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b638c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéâ Artefacts sauvegard√©s dans model\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(model, os.path.join(ARTIFACT_DIR, \"xgb_classifier_model.joblib\"))\n",
    "joblib.dump(vectorizer, os.path.join(ARTIFACT_DIR, \"reco_vectorizer.joblib\"))\n",
    "joblib.dump(svd, os.path.join(ARTIFACT_DIR, \"svd_model.joblib\"))\n",
    "joblib.dump(tfidf_matrix_full, os.path.join(ARTIFACT_DIR, \"tfidf_matrix_full.joblib\"))\n",
    "joblib.dump(mlb, os.path.join(ARTIFACT_DIR, \"mlb_model.joblib\"))\n",
    "joblib.dump(scaler_year, os.path.join(ARTIFACT_DIR, \"scaler_year.joblib\"))\n",
    "joblib.dump(nn_full, os.path.join(ARTIFACT_DIR, \"nn_full.joblib\"))\n",
    "\n",
    "#df[[\"movie_id\", \"title\"]].to_csv(os.path.join(ARTIFACT_DIR, \"movie_index_full.csv\"), index=False)\n",
    "#df.to_csv(os.path.join(ARTIFACT_DIR, \"movies_full.csv\"), index=False)\n",
    "\n",
    "print(\"üéâ Artefacts sauvegard√©s dans\", ARTIFACT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c956d902",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\loulo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\loulo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "c:\\Users\\loulo\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:13:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "2025/08/28 13:13:34 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "c:\\Users\\loulo\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:1028: UserWarning: [13:13:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\c_api\\c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "2025/08/28 13:13:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Pipeline classification termin√© ! Accuracy: 0.832 | AUC: 0.5694185487226879\n",
      "‚úÖ Mod√®le XGB sauvegard√© !\n",
      "‚úÖ TfidfVectorizer sauvegard√© !\n",
      "‚úÖ SVD sauvegard√© !\n",
      "‚úÖ TF-IDF matrix compl√®te sauvegard√©e !\n",
      "‚úÖ Movie index complet sauvegard√© !\n",
      "‚úÖ MultiLabelBinarizer sauvegard√© !\n",
      "‚úÖ StandardScaler pour l'ann√©e sauvegard√© !\n",
      "‚úÖ NearestNeighbors complet sauvegard√© !\n",
      "‚úÖ DataFrame complet sauvegard√© !\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import xgboost as xgb\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "import os\n",
    "import joblib\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "# =========================\n",
    "# 1. Charger les donn√©es\n",
    "# =========================\n",
    "DATABASE_URL = \"mysql+pymysql://louve:%40Marley080922@mysql-louve.alwaysdata.net/louve_movies\"\n",
    "engine = create_engine(DATABASE_URL)\n",
    "query = \"SELECT movie_id, title, synopsis, rating, genres, release_year FROM movies WHERE synopsis IS NOT NULL\"\n",
    "df = pd.read_sql(query, engine)\n",
    "\n",
    "# Nettoyage texte\n",
    "def preprocess_text(text: str) -> str:\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \" \", text)\n",
    "    return text\n",
    "\n",
    "df[\"synopsis_clean\"] = df[\"synopsis\"].apply(preprocess_text)\n",
    "\n",
    "# =========================\n",
    "# 2. TF-IDF + SVD sur tout le dataset\n",
    "# =========================\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words=\"english\")\n",
    "tfidf_matrix_full = vectorizer.fit_transform(df[\"synopsis_clean\"].fillna(\"\"))\n",
    "\n",
    "svd_full = TruncatedSVD(n_components=100, random_state=42)\n",
    "tfidf_svd_full = svd_full.fit_transform(tfidf_matrix_full)\n",
    "\n",
    "# =========================\n",
    "# 3. Genres et ann√©es\n",
    "# =========================\n",
    "df[\"genres_list\"] = df[\"genres\"].fillna(\"\").apply(lambda x: x.split(\"|\"))\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "genres_encoded_full = mlb.fit_transform(df[\"genres_list\"])\n",
    "\n",
    "scaler_year = StandardScaler()\n",
    "year_scaled_full = scaler_year.fit_transform(df[[\"release_year\"]].fillna(df[\"release_year\"].mean()))\n",
    "\n",
    "# =========================\n",
    "# 4. Nearest Neighbors sur full dataset\n",
    "# =========================\n",
    "nn_full = NearestNeighbors(metric=\"cosine\", algorithm=\"brute\")\n",
    "nn_full.fit(tfidf_matrix_full)\n",
    "distances_full, indices_full = nn_full.kneighbors(tfidf_matrix_full, n_neighbors=6)\n",
    "neighbor_scores_full = 1 - distances_full[:, 1:]\n",
    "\n",
    "sim_mean_full = neighbor_scores_full.mean(axis=1)\n",
    "sim_max_full = neighbor_scores_full.max(axis=1)\n",
    "sim_min_full = neighbor_scores_full.min(axis=1)\n",
    "sim_std_full = neighbor_scores_full.std(axis=1)\n",
    "\n",
    "# =========================\n",
    "# 5. √âchantillon pour entra√Ænement XGB\n",
    "# =========================\n",
    "df_sample = df.sample(10_000, random_state=42).reset_index(drop=True)\n",
    "\n",
    "tfidf_matrix_sample = vectorizer.transform(df_sample[\"synopsis_clean\"].fillna(\"\"))\n",
    "tfidf_svd_sample = svd_full.transform(tfidf_matrix_sample)\n",
    "\n",
    "genres_encoded_sample = mlb.transform(df_sample[\"genres_list\"])\n",
    "year_scaled_sample = scaler_year.transform(df_sample[[\"release_year\"]].fillna(df[\"release_year\"].mean()))\n",
    "\n",
    "nn_sample = NearestNeighbors(metric=\"cosine\", algorithm=\"brute\")\n",
    "nn_sample.fit(tfidf_matrix_sample)\n",
    "distances_sample, indices_sample = nn_sample.kneighbors(tfidf_matrix_sample, n_neighbors=6)\n",
    "neighbor_scores_sample = 1 - distances_sample[:, 1:]\n",
    "\n",
    "sim_mean_sample = neighbor_scores_sample.mean(axis=1)\n",
    "sim_max_sample = neighbor_scores_sample.max(axis=1)\n",
    "sim_min_sample = neighbor_scores_sample.min(axis=1)\n",
    "sim_std_sample = neighbor_scores_sample.std(axis=1)\n",
    "\n",
    "# Classification : like / dislike\n",
    "threshold = 7.0  # note >= 7 -> \"like\"\n",
    "y_class_sample = (df_sample[\"rating\"] >= threshold).astype(int)\n",
    "\n",
    "# Features\n",
    "X_sample = np.column_stack([\n",
    "    tfidf_svd_sample,\n",
    "    genres_encoded_sample,\n",
    "    year_scaled_sample,\n",
    "    sim_mean_sample,\n",
    "    sim_max_sample,\n",
    "    sim_min_sample,\n",
    "    sim_std_sample\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sample, y_class_sample, test_size=0.2, random_state=42)\n",
    "\n",
    "# =========================\n",
    "# 6. MLflow & XGB\n",
    "# =========================\n",
    "mlflow.set_experiment(\"movies_reco_pipeline_classif\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"xgb_hybrid_classif\"):\n",
    "    params = {\n",
    "        \"n_estimators\": 300,\n",
    "        \"max_depth\": 6,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1,\n",
    "        \"use_label_encoder\": False,\n",
    "        \"eval_metric\": \"logloss\"\n",
    "    }\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # √âvaluation\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    mlflow.log_metric(\"auc\", auc)\n",
    "    mlflow.xgboost.log_model(model, \"xgb_classifier_model\")\n",
    "\n",
    "print(\"‚úÖ Pipeline classification termin√© ! Accuracy:\", acc, \"| AUC:\", auc)\n",
    "\n",
    "# =========================\n",
    "# 7. Sauvegarde des artefacts\n",
    "# =========================\n",
    "os.makedirs(\"model\", exist_ok=True)\n",
    "\n",
    "# Sauvegarde du mod√®le\n",
    "joblib.dump(model, \"model/xgb_classifier_model.joblib\")\n",
    "print(\"‚úÖ Mod√®le XGB sauvegard√© !\")\n",
    "\n",
    "# Sauvegarde du vectorizer\n",
    "joblib.dump(vectorizer, \"model/reco_vectorizer.joblib\")\n",
    "print(\"‚úÖ TfidfVectorizer sauvegard√© !\")\n",
    "\n",
    "# Sauvegarde du SVD\n",
    "joblib.dump(svd_full, \"model/svd_model.joblib\")\n",
    "print(\"‚úÖ SVD sauvegard√© !\")\n",
    "\n",
    "# Sauvegarde de la TF-IDF matrix compl√®te\n",
    "joblib.dump(tfidf_matrix_full, \"model/tfidf_matrix_full.joblib\")\n",
    "print(\"‚úÖ TF-IDF matrix compl√®te sauvegard√©e !\")\n",
    "\n",
    "# Sauvegarde du movie index\n",
    "df[[\"movie_id\", \"title\"]].to_csv(\"model/movie_index.csv\", index=False)\n",
    "print(\"‚úÖ Movie index complet sauvegard√© !\")\n",
    "\n",
    "# Sauvegarde du MultiLabelBinarizer\n",
    "joblib.dump(mlb, \"model/mlb_model.joblib\")\n",
    "print(\"‚úÖ MultiLabelBinarizer sauvegard√© !\")\n",
    "\n",
    "# Sauvegarde du StandardScaler pour l'ann√©e\n",
    "joblib.dump(scaler_year, \"model/scaler_year.joblib\")\n",
    "print(\"‚úÖ StandardScaler pour l'ann√©e sauvegard√© !\")\n",
    "\n",
    "# Sauvegarde du NearestNeighbors complet\n",
    "joblib.dump(nn_full, \"model/nn_full.joblib\")\n",
    "print(\"‚úÖ NearestNeighbors complet sauvegard√© !\")\n",
    "\n",
    "# Sauvegarde du DataFrame complet\n",
    "df.to_csv(\"model/movies_full.csv\", index=False)\n",
    "print(\"‚úÖ DataFrame complet sauvegard√© !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b62c8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sqlalchemy import create_engine\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import (\n",
    "#     accuracy_score,\n",
    "#     roc_auc_score,\n",
    "#     precision_score,\n",
    "#     recall_score,\n",
    "#     f1_score,\n",
    "#     confusion_matrix,\n",
    "#     classification_report\n",
    "# )\n",
    "# import xgboost as xgb\n",
    "# import numpy as np\n",
    "# import re\n",
    "# import mlflow\n",
    "# import mlflow.xgboost\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "\n",
    "# # =========================\n",
    "# # 1Ô∏è‚É£ Charger les donn√©es\n",
    "# # =========================\n",
    "# DATABASE_URL = \"mysql+pymysql://louve:%40Marley080922@mysql-louve.alwaysdata.net/louve_movies\"\n",
    "# engine = create_engine(DATABASE_URL)\n",
    "# query = \"SELECT title, synopsis, rating, genres, release_year FROM movies WHERE synopsis IS NOT NULL\"\n",
    "# df = pd.read_sql(query, engine)\n",
    "\n",
    "# # =========================\n",
    "# # 2Ô∏è‚É£ Nettoyage texte\n",
    "# # =========================\n",
    "# def preprocess_text(text: str) -> str:\n",
    "#     text = text.lower()\n",
    "#     text = re.sub(r\"[^a-zA-Z0-9\\s]\", \" \", text)\n",
    "#     return text\n",
    "\n",
    "# df[\"synopsis_clean\"] = df[\"synopsis\"].apply(preprocess_text)\n",
    "\n",
    "# # =========================\n",
    "# # 3Ô∏è‚É£ Like/Dislike\n",
    "# # =========================\n",
    "# threshold = 4.0\n",
    "# df[\"like_dislike\"] = df[\"rating\"].apply(lambda x: 1 if x >= threshold else 0)\n",
    "\n",
    "# # =========================\n",
    "# # 4Ô∏è‚É£ Features : TF-IDF + genres + ann√©e\n",
    "# # =========================\n",
    "# vectorizer = TfidfVectorizer(max_features=2000, stop_words=\"english\")\n",
    "# tfidf_matrix = vectorizer.fit_transform(df[\"synopsis_clean\"].fillna(\"\"))\n",
    "\n",
    "# df[\"genres_list\"] = df[\"genres\"].fillna(\"\").apply(lambda x: x.split(\"|\"))\n",
    "# mlb = MultiLabelBinarizer()\n",
    "# genres_encoded = mlb.fit_transform(df[\"genres_list\"])\n",
    "\n",
    "# scaler_year = StandardScaler()\n",
    "# years_scaled = scaler_year.fit_transform(df[[\"release_year\"]].fillna(df[\"release_year\"].mean()))\n",
    "\n",
    "# X = np.column_stack([tfidf_matrix.toarray(), genres_encoded, years_scaled])\n",
    "# y = df[\"like_dislike\"].values\n",
    "\n",
    "# # =========================\n",
    "# # 5Ô∏è‚É£ Train/Test split\n",
    "# # =========================\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.2, random_state=42, stratify=y\n",
    "# )\n",
    "\n",
    "# # Calcul du scale_pos_weight apr√®s train/test split\n",
    "# scale_pos_weight = y_train.tolist().count(0) / y_train.tolist().count(1)\n",
    "\n",
    "# # =========================\n",
    "# # 6Ô∏è‚É£ MLflow & XGBoost\n",
    "# # =========================\n",
    "# mlflow.set_experiment(\"movies_like_dislike_classif\")\n",
    "\n",
    "# with mlflow.start_run(run_name=\"xgb_like_dislike\"):\n",
    "#     # Log du seuil et du scale_pos_weight\n",
    "#     mlflow.log_param(\"like_threshold\", threshold)\n",
    "#     mlflow.log_param(\"scale_pos_weight\", scale_pos_weight)\n",
    "\n",
    "#     # Param√®tres du mod√®le\n",
    "#     params = {\n",
    "#         \"n_estimators\": 200,\n",
    "#         \"max_depth\": 5,\n",
    "#         \"learning_rate\": 0.05,\n",
    "#         \"random_state\": 42,\n",
    "#         \"n_jobs\": -1,\n",
    "#         \"use_label_encoder\": False,\n",
    "#         \"eval_metric\": \"logloss\",\n",
    "#         \"scale_pos_weight\": scale_pos_weight\n",
    "#     }\n",
    "#     mlflow.log_params(params)\n",
    "\n",
    "#     # Entra√Ænement\n",
    "#     model = xgb.XGBClassifier(**params)\n",
    "#     model.fit(X_train, y_train)\n",
    "\n",
    "#     # Pr√©dictions\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "#     # Metrics\n",
    "#     acc = accuracy_score(y_test, y_pred)\n",
    "#     roc = roc_auc_score(y_test, y_prob)\n",
    "#     prec = precision_score(y_test, y_pred)\n",
    "#     rec = recall_score(y_test, y_pred)\n",
    "#     f1 = f1_score(y_test, y_pred)\n",
    "#     cm = confusion_matrix(y_test, y_pred)\n",
    "#     report = classification_report(y_test, y_pred)\n",
    "\n",
    "#     # Log des m√©triques\n",
    "#     mlflow.log_metric(\"accuracy\", acc)\n",
    "#     mlflow.log_metric(\"roc_auc\", roc)\n",
    "#     mlflow.log_metric(\"precision\", prec)\n",
    "#     mlflow.log_metric(\"recall\", rec)\n",
    "#     mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "#     # Log du mod√®le\n",
    "#     mlflow.xgboost.log_model(model, \"xgb_like_dislike_model\")\n",
    "\n",
    "#     print(\"‚úÖ Mod√®le logg√© sur MLflow avec seuil et scale_pos_weight !\")\n",
    "\n",
    "# print(\"Accuracy:\", acc)\n",
    "# print(\"ROC AUC:\", roc)\n",
    "# print(\"Precision:\", prec)\n",
    "# print(\"Recall:\", rec)\n",
    "# print(\"F1-score:\", f1)\n",
    "# print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "# print(\"\\nClassification Report:\\n\", report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
