{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee90b2a1",
   "metadata": {},
   "source": [
    "# Recommandation de film"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6362ce2d",
   "metadata": {},
   "source": [
    "## Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d8a9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import xgboost as xgb\n",
    "import mlflow\n",
    "import mlflow.xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff6511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# ⚙️ Config\n",
    "# =========================\n",
    "DATABASE_URL = os.getenv(\"MYSQL_URL\")\n",
    "if not DATABASE_URL:\n",
    "    raise RuntimeError(\"Missing MYSQL_URL\")\n",
    "\n",
    "SQL_QUERY = \"\"\"\n",
    "SELECT movie_id, title, synopsis, rating, genres, release_year\n",
    "FROM movies\n",
    "WHERE synopsis IS NOT NULL\n",
    "\"\"\"\n",
    "\n",
    "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\", mlflow.get_tracking_uri()))\n",
    "EXPERIMENT_NAME = \"monitoring_model-github\"\n",
    "RUN_NAME = \"monitoring_train\"\n",
    "\n",
    "LIKE_THRESHOLD = 4.0          # seuil like/dislike\n",
    "TFIDF_MAX_FEATURES = 5000\n",
    "SVD_COMPONENTS = 100\n",
    "RANDOM_STATE = 42\n",
    "SAMPLE_SIZE = 10_000          # None = tout le dataset\n",
    "\n",
    "ARTIFACT_DIR = \"E3_E4_API_app/model\"\n",
    "os.makedirs(ARTIFACT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b37246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text: str) -> str:\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \" \", text)\n",
    "    return text\n",
    "\n",
    "engine = create_engine(DATABASE_URL)\n",
    "df = pd.read_sql(SQL_QUERY, engine)\n",
    "\n",
    "df[\"synopsis_clean\"] = df[\"synopsis\"].fillna(\"\").apply(preprocess_text)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a37894f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=TFIDF_MAX_FEATURES, stop_words=\"english\")\n",
    "tfidf_matrix_full = vectorizer.fit_transform(df[\"synopsis_clean\"])\n",
    "\n",
    "# Réduction SVD\n",
    "svd = TruncatedSVD(n_components=SVD_COMPONENTS, random_state=RANDOM_STATE)\n",
    "tfidf_svd_full = svd.fit_transform(tfidf_matrix_full)\n",
    "\n",
    "# Genres\n",
    "def split_genres(s: str):\n",
    "    if not s: return []\n",
    "    return [g.strip() for g in s.split(\"|\") if g.strip()]\n",
    "\n",
    "df[\"genres_list\"] = df[\"genres\"].fillna(\"\").apply(split_genres)\n",
    "mlb = MultiLabelBinarizer()\n",
    "genres_encoded_full = mlb.fit_transform(df[\"genres_list\"])\n",
    "\n",
    "# Année\n",
    "scaler_year = StandardScaler()\n",
    "year_scaled_full = scaler_year.fit_transform(\n",
    "    df[[\"release_year\"]].fillna(df[\"release_year\"].mean())\n",
    ")\n",
    "\n",
    "# Similarité kNN\n",
    "nn_full = NearestNeighbors(metric=\"cosine\", algorithm=\"brute\")\n",
    "nn_full.fit(tfidf_matrix_full)\n",
    "distances_full, _ = nn_full.kneighbors(tfidf_matrix_full, n_neighbors=6)\n",
    "neighbor_scores_full = 1 - distances_full[:, 1:]\n",
    "\n",
    "sim_mean_full = neighbor_scores_full.mean(axis=1)\n",
    "sim_max_full = neighbor_scores_full.max(axis=1)\n",
    "sim_min_full = neighbor_scores_full.min(axis=1)\n",
    "sim_std_full = neighbor_scores_full.std(axis=1)\n",
    "\n",
    "sim_stats_full = np.column_stack([sim_mean_full, sim_max_full, sim_min_full, sim_std_full])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f30b325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label binaire\n",
    "y = (df[\"rating\"] >= LIKE_THRESHOLD).astype(int).to_numpy()\n",
    "\n",
    "# Features\n",
    "X_full = np.column_stack([tfidf_svd_full, genres_encoded_full, year_scaled_full, sim_stats_full])\n",
    "\n",
    "# Échantillonnage optionnel\n",
    "if SAMPLE_SIZE and SAMPLE_SIZE < len(df):\n",
    "    rng = np.random.default_rng(RANDOM_STATE)\n",
    "    idx = rng.choice(len(df), size=SAMPLE_SIZE, replace=False)\n",
    "    X = X_full[idx]\n",
    "    y = y[idx]\n",
    "    df_used = df.iloc[idx].reset_index(drop=True)\n",
    "else:\n",
    "    X = X_full\n",
    "    df_used = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f20115f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "n_pos = int((y_train == 1).sum())\n",
    "n_neg = int((y_train == 0).sum())\n",
    "scale_pos_weight = (n_neg / n_pos) if n_pos > 0 else 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66b94b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME):\n",
    "    params = {\n",
    "        \"colsample_bytree\": 0.935552788417904,\n",
    "        \"gamma\": 0.09983689107917987,\n",
    "        \"learning_rate\": 0.11256219891445009,\n",
    "        \"max_depth\": 3,\n",
    "        \"min_child_weight\": 3,\n",
    "        \"n_estimators\": 284,\n",
    "        \"subsample\": 0.7511572371061874,\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1,\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"use_label_encoder\": False,\n",
    "        \"scale_pos_weight\": scale_pos_weight,\n",
    "    }\n",
    "    mlflow.log_param(\"like_threshold\", LIKE_THRESHOLD)\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    roc = roc_auc_score(y_test, y_prob)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    mlflow.log_metric(\"roc_auc\", roc)\n",
    "    mlflow.log_metric(\"precision\", prec)\n",
    "    mlflow.log_metric(\"recall\", rec)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "    mlflow.xgboost.log_model(model, \"xgb_hybrid_like_dislike_model\")\n",
    "\n",
    "print(f\"✅ Metrics — ACC: {acc:.4f} | ROC-AUC: {roc:.4f} | P: {prec:.4f} | R: {rec:.4f} | F1: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975a6604",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(\"\\nClassification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b638c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(model, os.path.join(ARTIFACT_DIR, \"xgb_classifier_model.joblib\"))\n",
    "joblib.dump(vectorizer, os.path.join(ARTIFACT_DIR, \"reco_vectorizer.joblib\"))\n",
    "joblib.dump(svd, os.path.join(ARTIFACT_DIR, \"svd_model.joblib\"))\n",
    "joblib.dump(tfidf_matrix_full, os.path.join(ARTIFACT_DIR, \"tfidf_matrix_full.joblib\"))\n",
    "joblib.dump(mlb, os.path.join(ARTIFACT_DIR, \"mlb_model.joblib\"))\n",
    "joblib.dump(scaler_year, os.path.join(ARTIFACT_DIR, \"scaler_year.joblib\"))\n",
    "joblib.dump(nn_full, os.path.join(ARTIFACT_DIR, \"nn_full.joblib\"))\n",
    "\n",
    "# df.to_csv(os.path.join(ARTIFACT_DIR, \"movies_full.csv\"), index=False)\n",
    "\n",
    "print(\"🎉 Artefacts sauvegardés dans\", ARTIFACT_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
