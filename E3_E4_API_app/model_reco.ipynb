{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9409f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 Netflix\n",
      "337 Disney Plus\n",
      "119 Amazon Prime Video\n",
      "350 Apple TV+\n",
      "2 Apple TV\n",
      "283 Crunchyroll\n",
      "381 Canal+\n",
      "3 Google Play Movies\n",
      "58 Canal VOD\n",
      "147 M6+\n",
      "61 Orange VOD\n",
      "234 Arte\n",
      "192 YouTube\n",
      "188 YouTube Premium\n",
      "138 FILMO\n",
      "59 Bbox VOD\n",
      "35 Rakuten TV\n",
      "11 MUBI\n",
      "310 LaCinetek\n",
      "324 Cinemas a la Demande\n",
      "415 Animation Digital Network\n",
      "190 Curiosity Stream\n",
      "475 DOCSVILLE\n",
      "513 Shadowz\n",
      "538 Plex\n",
      "2077 Plex Channel\n",
      "546 WOW Presents Plus\n",
      "550 Tenk\n",
      "551 Magellan TV\n",
      "554 BroadwayHD\n",
      "559 Filmzie\n",
      "444 Dekkoo\n",
      "239 Universcine\n",
      "1967 Molotov TV\n",
      "567 True Story\n",
      "569 DocAlliance Films\n",
      "315 Hoichoi\n",
      "10 Amazon Video\n",
      "300 Pluto TV\n",
      "677 Eventive\n",
      "685 Cine+ OCS Amazon Channel \n",
      "588 MGM Amazon Channel\n",
      "201 MUBI Amazon Channel\n",
      "692 Cultpix\n",
      "701 FilmBox+\n",
      "1732 Universcine Amazon Channel\n",
      "1734 Filmo Amazon Channel\n",
      "1733 Action Max Amazon Channel\n",
      "1735 Insomnia Amazon Channel\n",
      "1736 Shadowz Amazon Channel\n",
      "1737 INA  madelen Amazon Channel\n",
      "1738 Benshi Amazon Channel\n",
      "1754 TF1+\n",
      "1771 Takflix\n",
      "309 Sun Nxt\n",
      "1796 Netflix Standard with Ads\n",
      "531 Paramount Plus\n",
      "582 Paramount+ Amazon Channel\n",
      "184 Universal Pictures\n",
      "1875 Runtime\n",
      "1887 BrutX Amazon Channel\n",
      "1889 Universal+ Amazon Channel\n",
      "1912 Apollo\n",
      "688 ShortsTV Amazon Channel\n",
      "1715 Shahid VIP\n",
      "542 filmfriend\n",
      "1860 Univer Video\n",
      "236 France TV\n",
      "1899 HBO Max\n",
      "2173 Anime Digital Network Amazon Channel\n",
      "2285 JustWatchTV\n",
      "1968 Crunchyroll Amazon Channel\n",
      "2286 VIVA by videofutur\n",
      "2303 Paramount Plus Premium\n",
      "2307 Premiere Max\n",
      "2358 Lionsgate+ Amazon Channels\n",
      "2330 Jolt Film\n",
      "2478 FOUND TV\n",
      "2472 HBO Max  Amazon Channel\n",
      "464 Kocowa\n",
      "2100 Amazon Prime Video with Ads\n",
      "2535 France TV Amazon Channel\n",
      "608 Love Nature Amazon Channel\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# üé¨ Entra√Ænement mod√®le reco Louve\n",
    "# ===============================\n",
    "import os\n",
    "import re\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, precision_score,\n",
    "    recall_score, f1_score, confusion_matrix, classification_report\n",
    ")\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler, MinMaxScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "import xgboost as xgb\n",
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "\n",
    "# ============ ‚öôÔ∏è Config ============\n",
    "DATABASE_URL = os.getenv(\"MYSQL_URL\")\n",
    "if not DATABASE_URL:\n",
    "    raise RuntimeError(\"Missing MYSQL_URL\")\n",
    "\n",
    "SQL_QUERY = \"\"\"\n",
    "SELECT movie_id, title, synopsis, rating, genres, release_year\n",
    "FROM movies\n",
    "WHERE synopsis IS NOT NULL\n",
    "\"\"\"\n",
    "\n",
    "LIKE_THRESHOLD = 4.0\n",
    "TFIDF_MAX_FEATURES = 5000\n",
    "SVD_COMPONENTS = 100\n",
    "RANDOM_STATE = 42\n",
    "SAMPLE_SIZE = 10_000\n",
    "ARTIFACT_DIR = \"E3_E4_API_app/model\"\n",
    "os.makedirs(ARTIFACT_DIR, exist_ok=True)\n",
    "\n",
    "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\", mlflow.get_tracking_uri()))\n",
    "EXPERIMENT_NAME = \"monitoring_model-github\"\n",
    "RUN_NAME = \"monitoring_train\"\n",
    "\n",
    "# ============ üì¶ Chargement donn√©es ============\n",
    "def preprocess_text(text: str) -> str:\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \" \", text)\n",
    "    return text\n",
    "\n",
    "engine = create_engine(DATABASE_URL)\n",
    "df = pd.read_sql(SQL_QUERY, engine)\n",
    "df[\"synopsis_clean\"] = df[\"synopsis\"].fillna(\"\").apply(preprocess_text)\n",
    "\n",
    "# ============ üî¢ Pr√©traitement ============\n",
    "# TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=TFIDF_MAX_FEATURES, stop_words=\"english\")\n",
    "tfidf_matrix_full = vectorizer.fit_transform(df[\"synopsis_clean\"])\n",
    "\n",
    "# SVD\n",
    "svd = TruncatedSVD(n_components=SVD_COMPONENTS, random_state=RANDOM_STATE)\n",
    "tfidf_svd_full = svd.fit_transform(tfidf_matrix_full)\n",
    "\n",
    "# Genres\n",
    "def split_genres(s: str):\n",
    "    if not s:\n",
    "        return []\n",
    "    return [g.strip() for g in s.split(\"|\") if g.strip()]\n",
    "\n",
    "df[\"genres_list\"] = df[\"genres\"].fillna(\"\").apply(split_genres)\n",
    "mlb = MultiLabelBinarizer()\n",
    "genres_encoded_full = mlb.fit_transform(df[\"genres_list\"])\n",
    "\n",
    "# Ann√©e\n",
    "scaler_year = StandardScaler()\n",
    "year_scaled_full = scaler_year.fit_transform(\n",
    "    df[[\"release_year\"]].fillna(df[\"release_year\"].mean())\n",
    ")\n",
    "\n",
    "# Similarit√© KNN (sur TF-IDF)\n",
    "nn_full = NearestNeighbors(metric=\"cosine\", algorithm=\"brute\")\n",
    "nn_full.fit(tfidf_matrix_full)\n",
    "distances_full, _ = nn_full.kneighbors(tfidf_matrix_full, n_neighbors=6)\n",
    "neighbor_scores_full = 1 - distances_full[:, 1:]\n",
    "\n",
    "sim_mean_full = neighbor_scores_full.mean(axis=1)\n",
    "sim_max_full = neighbor_scores_full.max(axis=1)\n",
    "sim_min_full = neighbor_scores_full.min(axis=1)\n",
    "sim_std_full = neighbor_scores_full.std(axis=1)\n",
    "sim_stats_full = np.column_stack([sim_mean_full, sim_max_full, sim_min_full, sim_std_full])\n",
    "\n",
    "# ============ üéØ Features + labels ============\n",
    "y = (df[\"rating\"] >= LIKE_THRESHOLD).astype(int).to_numpy()\n",
    "X_full = np.column_stack([tfidf_svd_full, genres_encoded_full, year_scaled_full, sim_stats_full])\n",
    "\n",
    "# √âchantillonnage\n",
    "if SAMPLE_SIZE and SAMPLE_SIZE < len(df):\n",
    "    rng = np.random.default_rng(RANDOM_STATE)\n",
    "    idx = rng.choice(len(df), size=SAMPLE_SIZE, replace=False)\n",
    "    X = X_full[idx]\n",
    "    y = y[idx]\n",
    "    df_used = df.iloc[idx].reset_index(drop=True)\n",
    "else:\n",
    "    X = X_full\n",
    "    df_used = df.reset_index(drop=True)\n",
    "\n",
    "# ============ ‚úÇÔ∏è Split train/test ============\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "n_pos = int((y_train == 1).sum())\n",
    "n_neg = int((y_train == 0).sum())\n",
    "scale_pos_weight = (n_neg / n_pos) if n_pos > 0 else 1.0\n",
    "\n",
    "# ============ ü§ñ Mod√®le XGB ============\n",
    "params = {\n",
    "    \"colsample_bytree\": 0.935552788417904,\n",
    "    \"gamma\": 0.09983689107917987,\n",
    "    \"learning_rate\": 0.11256219891445009,\n",
    "    \"max_depth\": 3,\n",
    "    \"min_child_weight\": 3,\n",
    "    \"n_estimators\": 284,\n",
    "    \"subsample\": 0.7511572371061874,\n",
    "    \"random_state\": RANDOM_STATE,\n",
    "    \"n_jobs\": -1,\n",
    "    \"eval_metric\": \"logloss\",\n",
    "    \"use_label_encoder\": False,\n",
    "    \"scale_pos_weight\": scale_pos_weight,\n",
    "}\n",
    "\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "with mlflow.start_run(run_name=RUN_NAME):\n",
    "    mlflow.log_param(\"like_threshold\", LIKE_THRESHOLD)\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # üéØ Calibration\n",
    "    xgb_calibrated = CalibratedClassifierCV(model, method='sigmoid', cv=5)\n",
    "    xgb_calibrated.fit(X_train, y_train)\n",
    "\n",
    "    # ‚öñÔ∏è Proba calibr√©es\n",
    "    y_pred = xgb_calibrated.predict(X_test)\n",
    "    y_prob = xgb_calibrated.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    roc = roc_auc_score(y_test, y_prob)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    mlflow.log_metric(\"roc_auc\", roc)\n",
    "    mlflow.log_metric(\"precision\", prec)\n",
    "    mlflow.log_metric(\"recall\", rec)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "    mlflow.xgboost.log_model(xgb_calibrated, \"xgb_hybrid_like_dislike_model\")\n",
    "\n",
    "    print(f\"‚úÖ Metrics ‚Äî ACC: {acc:.4f} | ROC-AUC: {roc:.4f} | P: {prec:.4f} | R: {rec:.4f} | F1: {f1:.4f}\")\n",
    "\n",
    "\n",
    "# ============ ü§ñ Matrice confusion ============\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(\"\\nClassification Report:\\n\", report)\n",
    "\n",
    "# ============ üì¶ Sauvegarde artefacts ============\n",
    "# Calibrated model\n",
    "joblib.dump(xgb_calibrated, os.path.join(ARTIFACT_DIR, \"xgb_classifier_model.joblib\"))\n",
    "\n",
    "# TF-IDF, SVD, kNN\n",
    "joblib.dump(vectorizer, os.path.join(ARTIFACT_DIR, \"reco_vectorizer.joblib\"))\n",
    "joblib.dump(svd, os.path.join(ARTIFACT_DIR, \"svd_model.joblib\"))\n",
    "joblib.dump(tfidf_matrix_full, os.path.join(ARTIFACT_DIR, \"tfidf_matrix_full.joblib\"))\n",
    "joblib.dump(nn_full, os.path.join(ARTIFACT_DIR, \"nn_full.joblib\"))\n",
    "\n",
    "# Genres, ann√©e\n",
    "joblib.dump(mlb, os.path.join(ARTIFACT_DIR, \"mlb_model.joblib\"))\n",
    "joblib.dump(scaler_year, os.path.join(ARTIFACT_DIR, \"scaler_year.joblib\"))\n",
    "\n",
    "# üéØ Sauvegarde scaler pour `proba_scaled`\n",
    "scaler_proba = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_proba.fit(y_prob.reshape(-1, 1))  # calibration pour API\n",
    "joblib.dump(scaler_proba, os.path.join(ARTIFACT_DIR, \"scaler_proba.joblib\"))\n",
    "\n",
    "print(\"üéâ Artefacts sauvegard√©s dans\", ARTIFACT_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
